---
tags:
title: chatGPT
date created: 2023-04-04
date modified: 2023-06-15
---

# chatGPT

## 局限

今天就来谈谈这件事，我要说，**ChatGPT 确实很神奇，是划时代的技术创新，但是不应该无限夸大。**

ChatGPT 有其局限，很多事情它做不到。[有人说](https://36kr.com/p/2149318642305545)，ChatGPT 标志着机器取代人类的"奇点时刻"，这是不对的。

他们忽略了最关键的一点：**ChatGPT 不是"通用人工智能"，而是一个语言模型。**

"通用人类智能"（artificial general intelligence，简写 AGI）是 AI 的终极目标，就是造出可以像人类那样全方位的推理、思考、分析的机器。如果能实现，人类就真的危险了。

但是，ChatGPT 不是 AGI，而是一个 LLM（Large Language Models，大规模语言模型）。所谓"语言模型"，就是只用来处理语言文字（或者符号体系）的 AI 模型，发现其中的规律，可以根据提示（prompt），自动生成符合这些规律的内容。

这就是说，**ChatGPT 只适用于有成文符号的领域。**  这带来两个局限。

（1）如果某个领域是非成文的，不能用符号记录表达，那么 ChatGPT 就无能为力。比如，人类的很多心理活动、潜意识、灵感、顿悟等等，ChatGPT 就没法模拟生成。

（2）第二个局限更致命，ChatGPT 要用现有的文字材料进行训练，发现的是那些材料包含的规律。这意味着，它不能生成超出人类已知规律的东西。

举例来说，**它不能证明未解决的数学猜想，也不能提出没有人发现过的科学发现。**

# 原理

分辨模型的强弱，有一个关键指标，就是看它有多少个参数。一般来说，参数的数量越多，模型就越强。

GPT-2 有15亿个参数，GPT-3 和 ChatGPT 有[1750亿个](https://developer.nvidia.com/zh-cn/blog/openai-presents-gpt-3-a-175-billion-parameters-language-model/)，GPT-4 没有公布这个指标，据传比上一代大5倍以上。

参数相当于模型预测时，所依据的神经网络的节点数量。**参数越多，就代表了模型所考虑的各种可能性越多，计算量越大，效果越好。**

既然参数越多越好，那么参数会无限增长吗？

答案是不会的，因为参数受到训练材料的制约。必需有足够的训练材料，才能计算出这些参数，**如果参数无限增长，训练材料势必也要无限增长。**

我看到的一种说法是，训练材料至少应该是参数的10倍。举例来说，一个区分猫照片和狗照片的模型，假定有1,000个参数，那么至少应该用10,000张图片来训练。

# 用法

## 修改总结文章

将自己写的全文丢进去，然后先让他作为读者来总结文章的重点，和自己想表达的进行比对；再让其作为编辑，指出文章中有哪些逻辑问题或模糊的地方，两者想加往往能得到一些不错的改进建议

# 如何开通

[获取实体信用卡和 SIM 卡](https://tj51bxige8.feishu.cn/docx/TSZBdBfynoBINux2htWcefrtnHc)

# vscode 插件

![](https://chelsechen-img.oss-cn-hangzhou.aliyuncs.com/20230216141547.png)
